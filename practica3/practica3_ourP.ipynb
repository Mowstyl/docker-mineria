{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica 3 - Multiclasificadores y selección de variables\n",
    "\n",
    "## Minería de Datos 2017/2018\n",
    "\n",
    "* [**Hernán Indíbil de La Cruz Calvo**](https://github.com/Mowstyl)\n",
    "* [**Alejandro Martín Simón Sánchez**](https://github.com/elssbbboy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta práctica se divide en dos partes:\n",
    "\n",
    "**Multiclasificadores:** estudiaremos la API de scikit para los modelos de tipo ensemble y veremos como entrenar, seleccionar y utilizar estos modelos.\n",
    "\n",
    "**Selección de variables:** veremos los distintos algoritmos de selección de variables disponibles en scikit y como aplicarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always load all scipy stack packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, integrate\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code configures matplotlib for proper rendering\n",
    "%matplotlib inline\n",
    "mpl.rcParams[\"figure.figsize\"] = \"8, 4\"\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=6470\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'target', 'target_names']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_diabetes\n",
    "dss = {}\n",
    "dss['wisconsin'] = load_breast_cancer()\n",
    "dss['pima'] = load_diabetes()\n",
    "dir(dss['wisconsin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, en dss['wisconsin'] tenemos los siguientes atributos:\n",
    "\n",
    "* DESCR: descripción del dataset, con numero de casos, codificación de los valores perdidos, atributos, información de los mismos además de estadísticos y información adicional sobre la obtención de los datos y su origen.\n",
    "* data: array de numpy con los valores de cada atributo para cada caso. En prácticas anteriores sería similar al train_atts o test_atts (aún no hemos hecho holdout), cambiando que no se utiliza pandas y no tenemos los nombres de las variables predictoras.\n",
    "* feature_names: nombres de las variables categóricas, usado como columna en pandas anteriormente. De esta forma, dfs['wisconsin'].data[n][m] indica un valor de la variable dfs['wisconsin'].feature_names[m].\n",
    "* target: array de numpy con los valores de la clase para cada instancia. No se trabaja con strings, sino que ha sido binarizada para trabajar con 0 y 1 (más eficiente que trabajar con strings).\n",
    "* target_names: nombres de los distintos valores que toma la variable categórica original. De esta forma si tenemos un 0 en target sabemos que tenemos que se clasifica como target_names[0], en este caso 'malignant'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'target']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(dss['pima'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, en dss['pima'] tenemos algunas diferencias con el dataset wisconsin:\n",
    "\n",
    "* En target ya no tenemos 0 y 1, ya que la variable clase no es categórica, sino una medida cuantitativa de la progresión de la enfermedad un año después de la baseline.\n",
    "* El atributo target_names no tiene sentido ya que no existe ninguna correspondencia como en wisconsin. La variable clase no es categórica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dssh = {}\n",
    "\n",
    "for ds in dss:\n",
    "    strat = None\n",
    "    if ('target_names' in dir(dss[ds])): # Solo tiene sentido estratificar si la clase es categórica\n",
    "        strat = dss[ds].target\n",
    "    \n",
    "    dssh[ds] = {'train': {}, 'test': {}}\n",
    "    dssh[ds]['train']['atts'], dssh[ds]['test']['atts'], dssh[ds]['train']['label'], dssh[ds]['test']['label'] = train_test_split(\n",
    "        dss[ds].data,\n",
    "        dss[ds].target,\n",
    "        random_state = seed,\n",
    "        stratify = strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    1. Generar una lista de datos muestreados (con/sin remplazo, con/sin muestreo de atributos)\\n    2. Aprender un clasificador para cada muestra\\n    3. Obtener predicciones para cada modelo\\n    4. Obtener la moda de dichas predicciones\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    1. Generar una lista de datos muestreados (con/sin remplazo, con/sin muestreo de atributos)\n",
    "    2. Aprender un clasificador para cada muestra\n",
    "    3. Obtener predicciones para cada modelo\n",
    "    4. Obtener la moda de dichas predicciones\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función lleva a cabo un muestreo de variables predictoras. Los parámetros que se le pueden pasar son:\n",
    "* atts: array con los casos, preferiblemente de numpy. train_atts.\n",
    "* label: array con la variable clase asociada a cada caso. train_label.\n",
    "* feature_names: nombres de las variables predictoras. Opcional.\n",
    "* n_samples: número de muestras a generar. Opcional.\n",
    "* best_features: parámetro que indica si se tomarán las mejores variables para cada muestra. Si hay reemplazo no tiene sentido, ya que las n muestras que genere serán idénticas. Opcional.\n",
    "* replace: parámetro que indica si el muestreo se realiza con reemplazo. Opcional.\n",
    "* random_state: parámetro que indica la semilla para generar números aleatorios, solo utilizada con best_features=False. Opcional.\n",
    "* k: número de variables en cada muestra en caso de haber reemplazo y que best_features=False. Opcional.\n",
    "\n",
    "Devuelve una tripla con:\n",
    "* Lista de muestras(solo los casos/atts).\n",
    "* Lista de muestras(solo la clase/label).\n",
    "* Lista de listas con nombres de variables predictoras usadas en cada muestra. Si no se especificó feature_names devuelve None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "def sampleFeatures(atts, label, feature_names=None, n_samples=4, best_features=True, replace=False,\n",
    "                   random_state=None, k=10):\n",
    "    if (random_state is not None and not best_features):\n",
    "        random.seed(random_state)\n",
    "    kaux = int(atts.shape[1]/n_samples)\n",
    "    ks = [kaux for i in range(0, n_samples)]\n",
    "    if (kaux * n_samples < atts.shape[1]):\n",
    "        ks[-1] += 1\n",
    "    \n",
    "    auxatts = atts[:,:]\n",
    "    fnames = None\n",
    "    if (feature_names is not None):\n",
    "        auxfname = feature_names[:]\n",
    "        fnames = []\n",
    "    \n",
    "    sample = []\n",
    "    labels = []\n",
    "    \n",
    "    for s in ks:\n",
    "        if (best_features):\n",
    "            sel = SelectKBest(k=s)\n",
    "            sel.fit(auxatts, label)\n",
    "            mask = sel.get_support()\n",
    "        else:\n",
    "            cols = s\n",
    "            if (replace):\n",
    "                cols = k\n",
    "            samp = random.sample(range(0, auxatts.shape[1]), cols)\n",
    "            mask = [i in samp for i in range(0, auxatts.shape[1])]\n",
    "        sample.append(auxatts[:,mask])\n",
    "        labels.append(label)\n",
    "        if (feature_names is not None):\n",
    "            fnames.append(auxfname[mask])\n",
    "            if(not replace):\n",
    "                auxfname = auxfname[np.invert(mask)]\n",
    "        if(not replace):\n",
    "            auxatts = auxatts[:,np.invert(mask)]\n",
    "    return np.array(sample), np.array(labels), np.array(fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función lleva a cabo el muestreo, sobre variables o sobre casos, con o sin reemplazo. Los parámetros que se le pueden pasar son:\n",
    "* atts: array con los casos, preferiblemente de numpy. train_atts.\n",
    "* label: array con la variable clase asociada a cada caso. train_label.\n",
    "* feature_names: nombres de las variables predictoras. Opcional.\n",
    "* n_samples: número de muestras a generar. Opcional.\n",
    "* sample_features: indica si el muestreo se realiza sobre los casos (False) o sobre las variables predictoras (True)\n",
    "* best_features: parámetro que indica si se tomarán las mejores variables para cada muestra. Si hay reemplazo no tiene sentido, ya que las n muestras que genere serán idénticas. Solo se toma si sample_features=True. Opcional.\n",
    "* replace: parámetro que indica si el muestreo se realiza con reemplazo (sobre las variables predictoras o sobre los casos según el valor de sample_features). Opcional.\n",
    "* random_state: parámetro que indica la semilla para generar números aleatorios, solo utilizada con best_features=False. Opcional.\n",
    "* k: número de variables en cada muestra en caso de haber reemplazo, sample_features=True y best_features=False. Opcional.\n",
    "\n",
    "Devuelve una tripla con:\n",
    "* Lista de muestras(solo los casos/atts).\n",
    "* Lista de muestras(solo la clase/label).\n",
    "* Lista de listas con nombres de variables predictoras usadas en cada muestra. Si no se especificó feature_names devuelve None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "def ourSample(atts, label, feature_names=None, random_state=None, n_samples=2,\n",
    "              replace=True, sample_features=False, best_features=True, k=10):\n",
    "    if (sample_features):\n",
    "        return sampleFeatures(atts, label, feature_names=feature_names, random_state=random_state,\n",
    "                              best_features=best_features, n_samples=n_samples, replace=replace, k=k)\n",
    "    elif(replace):\n",
    "        sample = []\n",
    "        labels = []\n",
    "        fnames = None\n",
    "        if (feature_names is not None):\n",
    "            fnames = []\n",
    "        for i in range(0, n_samples):\n",
    "            X, y = resample(atts, label, random_state=random_state, n_samples=n_samples, replace=True)\n",
    "            sample.append(X)\n",
    "            labels.append(y)\n",
    "            if (feature_names is not None):\n",
    "                fnames.append(feature_names)\n",
    "        return np.array(sample), np.array(labels), np.array(fnames)\n",
    "    else:\n",
    "        if (random_state is not None):\n",
    "            random.seed(random_state)\n",
    "        ncases = int(atts.shape[0]/n_samples)\n",
    "        ncss = [ncases for i in range(0, n_samples)]\n",
    "        if (ncases * n_samples < atts.shape[0]):\n",
    "            ncss[-1] += 1\n",
    "        auxatts = atts[:,:]\n",
    "        auxlabels = label[:]\n",
    "        sample = []\n",
    "        labels = []\n",
    "        fnames = None\n",
    "        if (feature_names is not None):\n",
    "            fnames = []\n",
    "        for nc in ncss:\n",
    "            samp = random.sample(range(0, auxatts.shape[0]), nc)\n",
    "            mask = [i in samp for i in range(0, auxatts.shape[0])]\n",
    "            sample.append(auxatts[mask])\n",
    "            labels.append(auxlabels[mask])\n",
    "            if (feature_names is not None):\n",
    "                fnames.append(feature_names)\n",
    "            auxatts = auxatts[np.invert(mask)]\n",
    "            auxlabels = auxlabels[np.invert(mask)]\n",
    "        return np.array(sample), np.array(labels), np.array(fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de uso:\n",
    "Vamos a generar una lista de 10 muestras en las que muestreemos las variables predictoras. Cada muestra tendrá 10 variables predictoras escogidas aleatoriamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, l, n = ourSample(dssh['wisconsin']['train']['atts'],\n",
    "                    dssh['wisconsin']['train']['label'],\n",
    "                    feature_names=dss['wisconsin'].feature_names, n_samples=10,\n",
    "                    replace=True, best_features=False, sample_features=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, en a[0] tenemos nuestra primera muestra, donde a[0][0] sería el primer caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.74100000e+01,   3.36100000e+02,   2.30200000e+00,\n",
       "         7.59500000e-03,   2.21900000e-02,   3.45100000e-03,\n",
       "         1.15400000e+01,   7.42200000e+01,   1.48600000e-01,\n",
       "         7.55200000e-02])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en l[0][0] se tendrá el valor de la clase para el primer caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En n[0] se tendrá el nombre de las variables predictoras usadas en la primera muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean perimeter', 'mean area', 'perimeter error',\n",
       "       'smoothness error', 'compactness error', 'fractal dimension error',\n",
       "       'worst radius', 'worst perimeter', 'worst compactness',\n",
       "       'worst fractal dimension'],\n",
       "      dtype='<U23')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez listo el método para realizar el muestreo, podemos proceder a diseñar el ensemble.\n",
    "Tomará como parámetros los necesarios para ajustar el algoritmo del muestreo además de el algoritmo que se usará para el ensemble. Dicho algoritmo vendrá dado con una clase cuyas instancias tengan implementados los métodos set_params, fit y predict. Además, se podrá dar otro parámetro al ensemble llamado params que se podrá usar para indicar los parámetros que se pasan a todas las instancias del algoritmo al crear el ensemble.\n",
    "Cabe destacar que en lugar de n_samples tendremos n_models, que indicará tanto el número de muestras como el número de estimadores generados.\n",
    "El ensemble implementará a su vez los métodos fit y predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleHome:\n",
    "    def __init__(self, est, random_state=None, n_models=2, replace=True,\n",
    "                 sample_features=False, best_features=True, k=10, params=None):\n",
    "        self.base = est\n",
    "        self.rstate = random_state\n",
    "        self.nmodels = n_models\n",
    "        self.replace = replace\n",
    "        self.sfeatures = sample_features\n",
    "        self.bfeatures = best_features\n",
    "        self.k = k\n",
    "        self.params = params\n",
    "        \n",
    "        self.ests = []\n",
    "        for i in range(0, n_models):\n",
    "            self.ests.append(est())\n",
    "            if (params is not None):\n",
    "                self.ests[i].set_params(params)\n",
    "        \n",
    "    def fit(self, atts, label, feature_names=None):\n",
    "        satts, slabels, sfname = ourSample(atts, label, feature_names=feature_names,\n",
    "                                           n_samples=self.nmodels, replace=self.replace, random_state=self.rstate,\n",
    "                                           best_features=self.bfeatures, sample_features=self.sfeatures)\n",
    "        self.satts = satts\n",
    "        self.slabels = slabels\n",
    "        self.sfname = sfname\n",
    "        for i in range(0, self.nmodels):\n",
    "            self.ests[i].fit(self.satts[i], self.slabels[i])\n",
    "    \n",
    "    def predict(self, atts):\n",
    "        predictions = np.array([est.predict(atts) for est in self.ests])\n",
    "        return predictions\n",
    "        #return np.stats.mode(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "ensemble = EnsembleHome(tree.DecisionTreeClassifier, random_state=seed, n_models=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.fit(dssh['wisconsin']['train']['atts'], dssh['wisconsin']['train']['label'], feature_names=dss['wisconsin'].feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "        0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "        0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1],\n",
       "       [1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "        0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "        0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0],\n",
       "       [1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "        1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "        1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.predict(dssh['wisconsin']['test']['atts'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
