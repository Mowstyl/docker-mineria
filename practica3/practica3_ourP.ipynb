{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica 3 - Multiclasificadores y selección de variables\n",
    "\n",
    "## Minería de Datos 2017/2018\n",
    "\n",
    "* [**Hernán Indíbil de La Cruz Calvo**](https://github.com/Mowstyl)\n",
    "* [**Alejandro Martín Simón Sánchez**](https://github.com/elssbbboy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta práctica se divide en dos partes:\n",
    "\n",
    "**Multiclasificadores:** estudiaremos la API de scikit para los modelos de tipo ensemble y veremos como entrenar, seleccionar y utilizar estos modelos.\n",
    "\n",
    "**Selección de variables:** veremos los distintos algoritmos de selección de variables disponibles en scikit y como aplicarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always load all scipy stack packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, integrate\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code configures matplotlib for proper rendering\n",
    "%matplotlib inline\n",
    "mpl.rcParams[\"figure.figsize\"] = \"8, 4\"\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=6470\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'target', 'target_names']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_diabetes\n",
    "dss = {}\n",
    "dss['wisconsin'] = load_breast_cancer()\n",
    "dss['pima'] = load_diabetes()\n",
    "dir(dss['wisconsin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, en dss['wisconsin'] tenemos los siguientes atributos:\n",
    "\n",
    "* DESCR: descripción del dataset, con numero de casos, codificación de los valores perdidos, atributos, información de los mismos además de estadísticos y información adicional sobre la obtención de los datos y su origen.\n",
    "* data: array de numpy con los valores de cada atributo para cada caso. En prácticas anteriores sería similar al train_atts o test_atts (aún no hemos hecho holdout), cambiando que no se utiliza pandas y no tenemos los nombres de las variables predictoras.\n",
    "* feature_names: nombres de las variables categóricas, usado como columna en pandas anteriormente. De esta forma, dfs['wisconsin'].data[n][m] indica un valor de la variable dfs['wisconsin'].feature_names[m].\n",
    "* target: array de numpy con los valores de la clase para cada instancia. No se trabaja con strings, sino que ha sido binarizada para trabajar con 0 y 1 (más eficiente que trabajar con strings).\n",
    "* target_names: nombres de los distintos valores que toma la variable categórica original. De esta forma si tenemos un 0 en target sabemos que tenemos que se clasifica como target_names[0], en este caso 'malignant'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'target']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(dss['pima'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, en dss['pima'] tenemos algunas diferencias con el dataset wisconsin:\n",
    "\n",
    "* En target ya no tenemos 0 y 1, ya que la variable clase no es categórica, sino una medida cuantitativa de la progresión de la enfermedad un año después de la baseline.\n",
    "* El atributo target_names no tiene sentido ya que no existe ninguna correspondencia como en wisconsin. La variable clase no es categórica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dssh = {}\n",
    "\n",
    "for ds in dss:\n",
    "    strat = None\n",
    "    if ('target_names' in dir(dss[ds])): # Solo tiene sentido estratificar si la clase es categórica\n",
    "        strat = dss[ds].target\n",
    "    \n",
    "    dssh[ds] = {'train': {}, 'test': {}}\n",
    "    dssh[ds]['train']['atts'], dssh[ds]['test']['atts'], dssh[ds]['train']['label'], dssh[ds]['test']['label'] = train_test_split(\n",
    "        dss[ds].data,\n",
    "        dss[ds].target,\n",
    "        random_state = seed,\n",
    "        stratify = strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
